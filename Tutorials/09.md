# Differential Privacy
- Methodoly of rigorously defining the goal of cryptographic primitives (or breaking them)
- Allowing the reduction of ability for anyone to break it 
- Schemes will not be invulnerable. 
- Differential privacy equips statistical figures with a measure of privacy loss
- Adversaries
  - Malicious entity that prevents users from their goal

## Linkage attacks
- Matching up databases containing sensitive and insneitive information which allows differentiation of sensitive data on the basis of the insensitive fields

## Differencing attack
- Exploit the relationship between certain pairs of statistics

## Big Bang Attack
- Small scale dataset against the entire database

## The kindness of strangers
- Personal information flow from one person to another through statistical learning systems

## The "Smoking Causes Cancer"
- Generalization of all members of the study
- Make the study beneficial for the entire humanity 
- Revise predictions about health
- When one person participates in the database, he would not be worse off than when not being in the sutd 

## Ideal Scenario vs Reality
- One curator and secret data
- Data usually not actually in one place and we can only abstract away the data through cryptography so that it looks like the ideal scenario 

## Randomized Response
- Generally two privacy concerns: Loss through data breaches or bad interactions between statistics
- Well known technique for the social sciences used to mask embarrassing or illegal behavior
- It's not a new idea 
- Recover statistics such as the approxixmate fraction of students who in engage in the behavior in question
- To decrease, instead of getting a set of question, they add an unrelated question
- Inject carefully designed random noise
- THe goal is to obscure the presence or iabscence of anything that can be identified as a singleton
- Property of being differentially private depends only on the data protection algorithm

## Formal definition of differential privacy
- D and D' adjacentdatabases, different by a single row but same number of entry
- Epsilon is a measure of privacy loss (the lower the better)
- M is the randomized database that provides differential privacy of strength epsion
- S is the set of outputs of M, smaller the better
- The output of D and D' should be pretthy much the same (but not exact) 

## Properties of Differential Privacy
- Addresses arbritary risks
  - With inclusion of one single thing, that ping in the database should not indicate that you are in the company or not
- Quantification of privacy loss
  - DIfferential privacy allows either data compromised or safe
    - The variable parameter allows the data to be kept safe
  - Given the two mechanisms, with the same output, which one incur smaller privacy loss. Give the same privacy loss, which one is closer to the true value?
- Automatic and oblivious composition
  - The risk both D and D' is at worst the epsilon of both added together
  - e.g. compound databases
  - Bigger databases will still be differentially private
- Group privacy
  - Small groups in the dataset can't be identified by the database
- Closure under post processing
  - Nobody can analyze the data you get in any way after you pull the data 

## Case study: Google 
- Randomized aggregatable privacy preserving ordinal response
  - Statistics about software in Chrome
  - Google's analysis claims that the epsilon is 2. The uper limmit is epsilon 8-9 per user.

## Case study: Apple
- Help discover usage pattern
- Mathematical noise to a small sample of the usage pattern
- macOS has an epsilon value of 6, iOS 10 with 14. iOS 11 has an epsilon value of 43.