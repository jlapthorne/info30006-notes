# Digital Privacy Rights, Then, Now and in the Future
Guest lecturer: Dr Peter Eckersley, EFF lead CS

When he was in uni, there were a lot of concerns about P2P. 

Among other things, he is interested in the theory of economics and theory of public goods. The current economy protections and regulations mostly protect properties of rivalrous groups. Governments decide to try and compound these policies into the same rivalrous groups, but they're actually public goods.

It's a better idea to get to the Bay Area since that's where all the money and skills are. People there know what to do with technology and who to write their checks to. 

## EFF
- EFF is a digital civil liberties organization, built by odd characters informed with technology. It's now almost a legal defense foundation. 
- Precedence: Decisions that act as laws written by judges, creating new laws in the court cases themselves. This is what EFF does, either affecting precedence or providing information on how precedences can affect tertiary parties.
- It was mostly digital activism 
- Wrote bits of software that changes the way people use or perceive the internet.
  - Let's Encrypt 
  - You have to deal with some crazy bureaucracy just to get a CA, and Let's Encrypt automates the process


## Downsides to Encryption
- It's a tool that has many consequences and use cases. 
- There are very few downsides to HTTPS unless if you need to perform surveillance. 
- We don't necessary think it's good for people to monitor what we are doing
- There was a time cryptography was banned, and considered a weaponry
- During the San Bernadino case, the iPhone cracking was just a stage play to win the debate; they got the data from unencrypted backups anyway, they just wanted to try win the case.

## Pervasiveness of Secure Messaging
- If the government is this broken, you'd be tempted to use surveillance methods to get some group of people, but you won't give these to them, either, so it's a contradiction. 
- So just try to get someone first rather than getting false positives.
- They once tried to analyze attacks by the highest point of contact from people, but they ended up raiding pizza places.
- In the Snowdean leaks, the NSA was able to extract all information of calls and SMS, violating US constitutional law. There's no way you'll get a probable cause to investigate everyone in the US

## BDA and AI
- So much hype on AI 
  - But how much of AI hype is real, and how much is it is speculative?
  - Policy implications
- The hype around AI is part of the actual process, but also with sci-fi assumptions
- Neural networks now outperform humans in simple image identification
  - Visual question answering - given natural language and image, computer responds to it. This is not yet solved. But the advances from when it started is really rapid.
  - It's also nice to think of the social implications of technology
- False positives in neural network analysis of bail settings 
  - Even they have biases to races...
  - ML algorithms are making it worse these days
  - The problems come from
    - Algorithms being trained on broken data - you're training the machine to be racist
    - The minute variable bias: If you have a ML system to predict something would be true in the future. When there is a true model probability, the things that actually drive it are usually not accessible to the model. 
      - Example: Trying to get data on the probability of you crashing, the variables include: How much do you tend to answer you phone, how easily tired out you are, your driving skills...
      - These can be hugely unfair to people to get in that web of correlation
      - False correlation: "Driving at night is dangerous" because of all the data about crashes at night.
      - This was the immediate/minute(?) variable.
- Equal Opportunity Machine Learning - how to correct out biases on known groups of people with biases 
  - You need a list of the protected categories of your data - gender, age, ethnicity...
  - It's still in research, but once you're out in the world and applying ML, you have to know the bias of the data (and hence your system) and apply measures to ignore these biasing data.
- How do you output an explanation of why the ML/NN made out the data it did?
- Multicout analysis: Tweak around the data a bit to get a more realistic prediction
- The Public School debacle
  - No Child Left Behind: Where education policies were once going with people feeling on how to teach kids, this program allows them to collect data. What makes teaching effective?
  - Collects all standardized testing information and get data. Schools with big improvements will get rewards, but the underperforming teachers will automatically fire.
  - If you try to measure something, but as soon as you try to create incentives, your metric will cease to work usefully.
  - Schools cut all their curriculum but all the questions in the test, and just teach them those things. They'd even cheat them.
  - This algorithm also fires teachers automatically.
- PageRank: Figuring out which pages are authoritive
  - Google invented this good metric until the kids tried doing SEO
- People should also not have the misconception that algorithms are better than humans - it isn't.
  - Companies are behind pushing these algorithms out as well
  - 

## Aaron Schwartz
- Pursued by the law enforcement 
- Co-founded Reddit
  - He didn't like how it turned out
- Worked on the Open Library Project
- Worked on RSS
- "We have to stop (SOPA/PIPA)" - helped out online campaigning organizations and write a campaign between techies
- We can't have DNS blacklists - and started Demand Progress. Also called the few people who actually created the DNS
- Contributed in rounding up people who built the internet to sign a proposal against SOPA/PIPA
- 