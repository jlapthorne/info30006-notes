# Privacy in the Modern World - Technicalities
- Recall that for each phone, you have a long trace of anything that it does. (Specio-temporal points)
- The time can be very precise, but the location is rather broad through triangulation
- All we know as far as location goes is briefed from the triangulation of cell phone towers
- Triangulation, because all you need is a triangle of towers to get a good fix of where you are
- You must need some kind of verification between data points to distinguish one person to another if you have nothing else to track them with.
- If you can spot a couple of independent facts, the 2-3 independent data points is enough to make you unique.
  - Even if we take quite large areas, that trajectory of where you went might still be unique.
- Blurring times and spaces
  - Instead of having the person's exact cell tower, blend other towers and take wider and wider sets
  - As we blur time and space information, we still get more uniquness
- When we are talking about uniquness, what can we assume that the attacker knows about you?
- They are, however, just spatio-temoral points, and they can't really pinpoint who's who and who they contact just by this data.
- A lot of this information is available to corporations. Telcos, Google knows this kind of data.

## How not to find yourself....
- Consider this example
  - 3 million patients
  - 17310 women share year of birth
  - Had two children in 2006 and 2011
    - 59 possible matches, 25 in Victoria
  - Exact birthdates +/- 14 days
    - Luckily no date
- It's really, really easy to pick someone out.
- Re-identification is always possible when the dataset is updated

## Aggregate Queries
- How many federal MPs have HIV?
  - *this was leaked when Cori Bernadi was still in Liberal*
- How many Liberal Senators have had tuberculosis?
- This data may change over the next week...
  - If you ask this, you expose the fact of a particular individual even if you're asking very general questions

## Differential Privacy
- Technique that comes out of a research committee by thinking of the idea of how you distinguish somebody from the rest of the crowd
- check slides/recording

```
        Y    Say No
Truth
Y       3/4  1/4
N       1/4  3/4

Suppose x says yes, 1-x says no
Truth = (x-1/4) * 2
      = 2x - 1/2


```

- It depends on the ratio of the different values and the ability to compute the truth formula accurately
- Related queries leak even more information
- Precise and proper definition:
  - If for every two neighboring databases D1 and D2, the distributions of mechanism M in D1 and D2 are close. (the two databases are differentially private?)
  - DWork et al 2006
- We're trying to hide information of that one person, by arguing that if the person is added to the database, it's not going to change anything to the data
- We add randomness to the data to make sure that it doesn't change very much when real responses are taken out to preserve some privacy
- Two databases in R^(nxd) neighbor if differ on one row
- A mechanism is a random function on a DB
- To identify if someone is there, this returns 1 or 0 if the database has something about someone. Those two neighboring databases can be easily distinguished in this case.
- In particular, this allows us to protect queries against *one* individual in this definition
-
